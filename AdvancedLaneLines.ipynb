{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "***\n",
    "\n",
    "---\n",
    "The steps for the project is:\n",
    "1.    Camera calibration\n",
    "2.    Distortion correction\n",
    "3.    Color/gradient threshold\n",
    "4.    Perspective transform\n",
    "\n",
    "Thereafter:\n",
    "\n",
    "-    Detect lane lines\n",
    "-    Determine the lane curvature\n",
    "-    Determine the vehicle position in the lane\n",
    "\n",
    "In the end we transform the detected lane lines back to the distorted image to be able to plot them in the video.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Import needed packages**\n",
    "---\n",
    "Run the following cell to import all packages needed for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import some useful packages\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Calibrating the camera** \n",
    "\n",
    "---\n",
    "The camera is calibrated by using the chessboard images in the camera_cal folder.\n",
    "\n",
    "The steps of calibration are:\n",
    "* Find chessboard corners\n",
    "* Calibrate camera based on object points and image points\n",
    "\n",
    "---\n",
    "**Note that calibration only needs to be done once. The calibration data is saved and can be loaded and used in the undistortion instead of redoing the calibration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the chessboard corners\n",
    "\n",
    "# define number of rows and columns in calibration images\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# arrays to store object points and image points of all images\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# prepare object points\n",
    "objp = np.zeros((nx*ny,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "# create list of calibration images\n",
    "testImages = glob.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(testImages):\n",
    "    # Load image\n",
    "    img = mpimg.imread(fname)\n",
    "    # Gray scale (BGR since using opencv load function)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        '''\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "        '''\n",
    "\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calibrate camera\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = mpimg.imread('camera_cal/calibration2.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,imgpoints,img_size,None,None)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open(\"camera_cal/calibration_dist_pickle.p\", \"wb\"))\n",
    "\n",
    "undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(undst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "f.savefig('test_images/test_undst.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Undistorting image**\n",
    "---\n",
    "\n",
    "The images are corrected by applying the undistortion function based on the calibration data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Undistort image\n",
    "\n",
    "# Load camera calibration\n",
    "dist_pickle = pickle.load(open(\"camera_cal/calibration_dist_pickle.p\", \"rb\"))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Load image for distortion\n",
    "img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "f.savefig('test_images/straight_lines1_undst.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Color/gradient thresholding**\n",
    "\n",
    "---\n",
    "To determine where the lane markings are we will need to make sure to find them properly, being able to detect all kinds of lane markings and in all kinds of situations.\n",
    "\n",
    "Steps considered were:\n",
    "- Sobel operator in x and y (derivative of the image)\n",
    "- Magnitude thresholding\n",
    "- Direction thresholding\n",
    "- Color thresholding\n",
    "\n",
    "The colour spaces considered:\n",
    "- gray\n",
    "- HLS\n",
    "- Red channel in RGB image\n",
    "- Saturation channel in HLS image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions to be used for thresholding\n",
    "\n",
    "# Function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    \n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobelxy = cv2.Sobel(img, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobelxy = cv2.Sobel(img, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    absSobel = np.absolute(sobelxy)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    bitSobel = np.int8(255*absSobel/np.max(absSobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    sxbinary = np.zeros_like(bitSobel)\n",
    "    sxbinary[(bitSobel >= thresh[0]) & (bitSobel <= thresh[1])] = 1\n",
    "    return sxbinary\n",
    "\n",
    "# Function that applies Sobel x and y, \n",
    "# then computes the magnitude of the gradient\n",
    "# and applies a threshold\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude\n",
    "    sobel_mag = np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    intSobel = np.int8(255*sobel_mag/np.max(sobel_mag))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(intSobel)\n",
    "    binary_output[(intSobel >= mag_thresh[0]) & (intSobel <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# Function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    direction = np.arctan2(abs_sobely,abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(direction)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def binary_S(S_image, thresh=(0,255)):\n",
    "    binary = np.zeros_like(S_image)\n",
    "    binary[(S_image > thresh[0]) & (S_image <= thresh[1])] = 1\n",
    "    \n",
    "    return binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform combined thresholding\n",
    "\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "# Read in an image\n",
    "#img = mpimg.imread('test_images/extratest.jpg')\n",
    "img = mpimg.imread('test_images/straight_lines2.jpg')\n",
    "\n",
    "# Perform image undistortion\n",
    "image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Convert image to chosen colour spaces\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "HLS = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "S = HLS[:,:,2]\n",
    "R = image[:,:,0]\n",
    "\n",
    "# Apply each of the thresholding functions\n",
    "gradx = abs_sobel_thresh(R, orient='x', sobel_kernel=ksize, thresh=(30,100))\n",
    "grady = abs_sobel_thresh(R, orient='y', sobel_kernel=ksize, thresh=(30, 100))\n",
    "mag_binary = mag_thresh(R, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "dir_binary = dir_threshold(R, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "s_binary = binary_S(S,(170,255))\n",
    "gradxS = abs_sobel_thresh(S, orient='x', sobel_kernel=ksize, thresh=(20,100))\n",
    "gradyS = abs_sobel_thresh(S, orient='y', sobel_kernel=ksize, thresh=(30,100))\n",
    "mag_binaryS = mag_thresh(S, sobel_kernel=ksize, mag_thresh=(30,100))\n",
    "dir_binaryS = dir_threshold(S, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "# Combine thresholding functions\n",
    "combined = np.zeros_like(dir_binary)\n",
    "#combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "combined[((gradx == 1) & (grady == 1))| ((gradxS == 1) & (gradyS == 1))] = 1\n",
    "\n",
    "color_binary = np.dstack(( np.zeros_like(gradx), gradxS, s_binary))\n",
    "\n",
    "\n",
    "# Plot the result\n",
    "f, axes = plt.subplots(4, 3, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "axes[0,0].imshow(image)\n",
    "axes[0,0].set_title('Original Image', fontsize=15)\n",
    "axes[0,1].imshow(combined,cmap='gray')\n",
    "axes[0,1].set_title('Combined image',fontsize=15)\n",
    "axes[0,2].imshow(gradx, cmap='gray')\n",
    "axes[0,2].set_title('Grad x R image', fontsize=15)\n",
    "\n",
    "axes[1,0].imshow(gradxS, cmap='gray')\n",
    "axes[1,0].set_title('Grad x S image', fontsize=15)\n",
    "axes[1,1].imshow(grady,cmap='gray')\n",
    "axes[1,1].set_title('Grad y R image',fontsize=15)\n",
    "axes[1,2].imshow(gradyS,cmap='gray')\n",
    "axes[1,2].set_title('Grad y S image',fontsize=15)\n",
    "\n",
    "axes[2,0].imshow(mag_binary,cmap='gray')\n",
    "axes[2,0].set_title('Magnitude R image',fontsize=15)\n",
    "axes[2,1].imshow(mag_binaryS,cmap='gray')\n",
    "axes[2,1].set_title('Magnitude S image',fontsize=15)\n",
    "axes[2,2].imshow(dir_binary,cmap='gray')\n",
    "axes[2,2].set_title('Gradient direction R image',fontsize=15)\n",
    "\n",
    "axes[3,0].imshow(dir_binaryS,cmap='gray')\n",
    "axes[3,0].set_title('Gradient direction S image',fontsize=15)\n",
    "axes[3,1].imshow(s_binary,cmap='gray')\n",
    "axes[3,1].set_title('S binary image',fontsize=15)\n",
    "axes[3,2].imshow(color_binary,cmap='gray')\n",
    "axes[3,2].set_title('Color binary image',fontsize=15)\n",
    "#axes[2,1].imshow(color_binary,cmap='gray')\n",
    "#axes[2,1].set_title('Color binary image',fontsize=15)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perform extra image processing\n",
    "--- \n",
    "To get rid of unneccessary information cropping of the image is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function used for extra image processing\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (1,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 1\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Process image further\n",
    "\n",
    "# only region of interest\n",
    "imshape = np.shape(combined)\n",
    "vertices = np.array([[(100,imshape[0]),(imshape[1]/2-20,imshape[0]/2+50),(imshape[1]/2+40,imshape[0]/2+50),(imshape[1]-50,imshape[0])]], dtype=np.int32)\n",
    "masked_combined = region_of_interest(combined,vertices)\n",
    "\n",
    "# Plot the result\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "axes[0].imshow(combined, cmap='gray')\n",
    "axes[0].set_title('Before cropping Image', fontsize=30)\n",
    "axes[1].imshow(masked_combined, cmap='gray')\n",
    "axes[1].set_title('After cropping image', fontsize=30)\n",
    "#axes[1].plot(680,410,'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Perspective Transform**\n",
    "---\n",
    "The perspective transform is based on a lane images with straight lines. In these images, points on the lane lines were chosen as source points. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ref_right = 940 # reference value for right lane marking\n",
    "ref_left = 340 # reference value for left lane marking\n",
    "\n",
    "# image should be combined image from thresholding\n",
    "undist_img = masked_combined\n",
    "\n",
    "# create 3-channel image to draw on\n",
    "draw_img = cv2.cvtColor(np.uint8(undist_img*255), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# use straight camera image to find points, use these for all images\n",
    "src = np.float32([[215, 710], [595, 450], [690, 450], [1100, 710]])\n",
    "dst = np.float32([[ref_left,np.shape(undist_img)[0]], [ref_left,0], [ref_right,0], [ref_right,np.shape(undist_img)[0]]])\n",
    "\n",
    "cv2.polylines(draw_img, np.int32([src]), True, (0,0,255),2)\n",
    "\n",
    "# Compute perspective transform\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "# Warp the image (make the transform)\n",
    "warped = cv2.warpPerspective(undist_img, M, (np.shape(undist_img)[1],np.shape(undist_img)[0]), flags=cv2.INTER_LINEAR)\n",
    "verify_warped = cv2.warpPerspective(draw_img, M, (np.shape(draw_img)[1],np.shape(draw_img)[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "axes[0].imshow(draw_img,cmap='gray')\n",
    "axes[0].set_title('Undistorted Image', fontsize=30)\n",
    "# Plot additional points to check what to use for perspective transform\n",
    "#axes[0].plot([215,595,690,1100], [710,450,450,710])\n",
    "#axes[0].plot([640, 640],[0,720])\n",
    "#plt.show()\n",
    "axes[1].imshow(verify_warped,cmap='gray')\n",
    "axes[1].set_title('Warped image', fontsize=30)\n",
    "#axes[1].plot([ref_left,ref_left,ref_right,ref_right], [np.shape(undist_img)[0],0,0,np.shape(undist_img)[0]])\n",
    "#axes[1].plot(360,720,'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Detect lane lines and find equation**\n",
    "***\n",
    "\n",
    "Using histogram method to find lane lines and a second order polonomial to find equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "histogram = np.sum(warped[np.int32(warped.shape[0]/2):,:], axis=0)\n",
    "#plt.plot(histogram)\n",
    "\n",
    "# Create an output image to draw on and visualize the result\n",
    "# Transform value range to 0-255\n",
    "warped_copy = np.uint8(warped*255)\n",
    "# Create 3-channel image to be able to draw colour\n",
    "out_img = cv2.cvtColor(warped_copy, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]/2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set height of windows\n",
    "window_height = np.int(warped.shape[0]/nwindows)\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n",
    "\n",
    "# Step through the windows one by one\n",
    "for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "    win_y_low = warped.shape[0] - (window+1)*window_height\n",
    "    win_y_high = warped.shape[0] - window*window_height\n",
    "    win_xleft_low = leftx_current - margin\n",
    "    win_xleft_high = leftx_current + margin\n",
    "    win_xright_low = rightx_current - margin\n",
    "    win_xright_high = rightx_current + margin\n",
    "    # Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "    good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "    good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "    left_lane_inds.append(good_left_inds)\n",
    "    right_lane_inds.append(good_right_inds)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "    if len(good_left_inds) > minpix:\n",
    "        leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "    if len(good_right_inds) > minpix:        \n",
    "        rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "# Concatenate the arrays of indices\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "plt.imshow(out_img)\n",
    "\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Assume you now have a new warped binary image \n",
    "# from the next frame of video (also called \"warped\")\n",
    "# It's now much easier to find line pixels!\n",
    "nonzero = warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "margin = 100\n",
    "left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "# Again, extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds]\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create an image to draw on and an image to show the selection window\n",
    "warped_copy = np.uint8(warped*255)\n",
    "# Create 3-channel image to be able to draw colour\n",
    "out_img = cv2.cvtColor(warped_copy, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "window_img = np.zeros_like(out_img)\n",
    "# Color in left and right line pixels\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ***Determine lane curvature and vehicle position***\n",
    "***\n",
    "The vehicle position is calculated based on the offset of the lane markings to the middle of the camera image (we assume that the camera is placed in the middle of the vehicle).\n",
    "\n",
    "The curvature is calculated for each lane marking (left and right) based on an equation which is explained [here](http://www.intmath.com/applications-differentiation/8-radius-curvature.php).\n",
    "\n",
    "Conversion from pixels to meters is also made for both cases, which is defined based on pixel values in the warped (transformed) image and the assumption that the lane width is 3,7m and that we are predicting 30m ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Determine vehicle position\n",
    "\n",
    "lane_w_pxls = ref_right-ref_left\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/lane_w_pxls # meters per pixel in x dimension (pixels is lane width in warped image)\n",
    "\n",
    "# middle of lane should be in the middle of the image (camera is assumed to be centered in vehicle)\n",
    "norm_middle = warped.shape[1]/2\n",
    "\n",
    "diff_right = rightx_base-norm_middle-lane_w_pxls/2\n",
    "\n",
    "if diff_right > 0:\n",
    "    # we are located to the left   \n",
    "    vehPos_text = str(round(np.absolute(diff_right)*xm_per_pix,2)) + 'm to the left of middle' #make conversion to get in m\n",
    "elif diff_right < 0:\n",
    "    # we are located to the right\n",
    "    vehPos_text = str(round(np.absolute(diff_right)*xm_per_pix,2)) + 'm to the right of middle' #make conversion to get in m\n",
    "else:\n",
    "    # we are located in the middle \n",
    "    vehPos_text = 'in the middle'\n",
    "    \n",
    "print(vehPos_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Determine lane curvature based on vehicle position\n",
    "\n",
    "# Define y-value where we want radius of curvature\n",
    "# I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "y_eval = warped.shape[0]    \n",
    "\n",
    "# Fit new polynomials to x,y in world space\n",
    "left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "# Calculate the new radii of curvature\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "# Radius of curvature in meters\n",
    "print(left_curverad, 'm', right_curverad, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ** Convert back to original view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# image is undistorted image, this is the image to draw on\n",
    "# First perspective transform\n",
    "warped_out = cv2.warpPerspective(image, M, (np.shape(image)[1],np.shape(image)[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Draw lane surface on it\n",
    "xy_plot = np.zeros((1,np.shape(ploty)[0]*2,2))\n",
    "xy_plot[:,0:np.shape(ploty)[0],0] = left_fitx\n",
    "xy_plot[:,0:np.shape(ploty)[0],1] = ploty\n",
    "xy_plot[:,np.shape(ploty)[0]:,0] = right_fitx[::-1]\n",
    "xy_plot[:,np.shape(ploty)[0]:,1] = ploty[::-1]\n",
    "\n",
    "cv2.fillConvexPoly(warped_out, np.int_(xy_plot), (255,0,0))\n",
    "\n",
    "# Compute inverse perspective transform\n",
    "invM = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "# Unwarp the image\n",
    "unwarped = cv2.warpPerspective(warped_out, invM, (np.shape(warped_out)[1],np.shape(warped_out)[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Put images together\n",
    "result = cv2.addWeighted(image, 1, unwarped, 0.3, 0)\n",
    "\n",
    "# Add curvature and vehicle position texts\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "curve_text = 'Left: '+str(round(left_curverad,2)) + 'm. Right: ' + str(round(right_curverad,2)) + 'm.'\n",
    "cv2.putText(result, curve_text, (400,50), font, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "cv2.putText(result, vehPos_text, (400,100), font, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "axes[0].imshow(warped_out)\n",
    "axes[0].set_title('Warped Image', fontsize=15)\n",
    "axes[1].imshow(result)\n",
    "axes[1].set_title('Unwarped image', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# **Setting up project structure**\n",
    "--- \n",
    "Code below is used to input an image and perform all the processing needed to get the output image with marked lane, curvature and vehicle position text. It is a summary of what is done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions to be used for thresholding\n",
    "\n",
    "# Function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    \n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobelxy = cv2.Sobel(img, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobelxy = cv2.Sobel(img, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    absSobel = np.absolute(sobelxy)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    bitSobel = np.int8(255*absSobel/np.max(absSobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    sxbinary = np.zeros_like(bitSobel)\n",
    "    sxbinary[(bitSobel >= thresh[0]) & (bitSobel <= thresh[1])] = 1\n",
    "    return sxbinary\n",
    "\n",
    "# Function that applies Sobel x and y, \n",
    "# then computes the magnitude of the gradient\n",
    "# and applies a threshold\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude\n",
    "    sobel_mag = np.sqrt(np.square(sobelx)+np.square(sobely))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    intSobel = np.int8(255*sobel_mag/np.max(sobel_mag))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(intSobel)\n",
    "    binary_output[(intSobel >= mag_thresh[0]) & (intSobel <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# Function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    direction = np.arctan2(abs_sobely,abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(direction)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def binary_S(S_image, thresh=(0,255)):\n",
    "    binary = np.zeros_like(S_image)\n",
    "    binary[(S_image > thresh[0]) & (S_image <= thresh[1])] = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "\n",
    "# Function used for extra image processing\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (1,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 1\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All project base line\n",
    "\n",
    "def preprocessImage(undist):\n",
    "    # Preprocess image to find lane markings in all situations    \n",
    "    \n",
    "    # TUNABLE PARAMETERS\n",
    "    # Sobel kernel size\n",
    "    ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "    \n",
    "    # PERFORM IMAGE THRESHOLDING    \n",
    "    # Convert image to chosen colour spaces\n",
    "    HLS = cv2.cvtColor(undist,cv2.COLOR_RGB2HLS)\n",
    "    S = HLS[:,:,2]\n",
    "    R = undist[:,:,0]\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(R, orient='x', sobel_kernel=ksize, thresh=(30,100))\n",
    "    grady = abs_sobel_thresh(R, orient='y', sobel_kernel=ksize, thresh=(30, 100))\n",
    "    #mag_binary = mag_thresh(R, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    #dir_binary = dir_threshold(R, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "    #s_binary = binary_S(S,(170,255))\n",
    "    gradxS = abs_sobel_thresh(S, orient='x', sobel_kernel=ksize, thresh=(20,100))\n",
    "    gradyS = abs_sobel_thresh(S, orient='y', sobel_kernel=ksize, thresh=(30,100))\n",
    "    #mag_binaryS = mag_thresh(S, sobel_kernel=ksize, mag_thresh=(30,100))\n",
    "    #dir_binaryS = dir_threshold(S, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "    # Combine thresholding functions\n",
    "    combined = np.zeros_like(R)\n",
    "    combined[((gradx == 1) & (grady == 1))| ((gradxS == 1) & (gradyS == 1))] = 1    \n",
    "    \n",
    "    # USE ONLY REGION OF INTEREST\n",
    "    imshape = np.shape(combined)\n",
    "    vertices = np.array([[(100,imshape[0]),(imshape[1]/2-20,imshape[0]/2+50),(imshape[1]/2+40,imshape[0]/2+50),(imshape[1]-50,imshape[0])]], dtype=np.int32)\n",
    "    masked_combined = region_of_interest(combined,vertices)    \n",
    "    \n",
    "    return masked_combined\n",
    "\n",
    "def transformImg(undist_img,src,dst):\n",
    "# Function that performs perspective transform on an image\n",
    "\n",
    "    # Compute perspective transform\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    # Warp the image\n",
    "    warped = cv2.warpPerspective(undist_img, M, (np.shape(undist_img)[1],np.shape(undist_img)[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, M\n",
    "\n",
    "def findLaneMarkingsNew(warped):\n",
    "    # Function to find the lane markings from scratch using Histogram approach\n",
    "    \n",
    "    histogram = np.sum(warped[np.int32(warped.shape[0]/2):,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "      \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty\n",
    "\n",
    "def findLaneMarkingsCont(warped,left_fit,right_fit):\n",
    "    # Function to detect lane markings when we already have a starting point from earlier found ones\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty\n",
    "\n",
    "def detCurvature(y_eval,leftx,lefty,rightx,righty,xm_per_pix,ym_per_pix):\n",
    "    # Function to determine lane curvature in meters    \n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def vehiclePos(norm_middle,right_fit,y,lane_w_pxls,xm_per_pix):\n",
    "# Function to determine vehicle position in lane\n",
    "\n",
    "    # Get x value for base of lane marking\n",
    "    rightx_base = right_fit[0]*(y**2) + right_fit[1]*y + right_fit[2] \n",
    "\n",
    "    # Calculate difference between where we expect the lane marking to be and where it is\n",
    "    diff_right = rightx_base-norm_middle-lane_w_pxls/2\n",
    "        \n",
    "    if diff_right > 0:\n",
    "        # we are located to the left   \n",
    "        vehPos_text = str(round(np.absolute(diff_right)*xm_per_pix,2)) + 'm to the left of middle' #make conversion to get in m\n",
    "    elif diff_right < 0:\n",
    "        # we are located to the right\n",
    "        vehPos_text = str(round(np.absolute(diff_right)*xm_per_pix,2)) + 'm to the right of middle' #make conversion to get in m\n",
    "    else:\n",
    "        # we are located in the middle \n",
    "        vehPos_text = 'in the middle'  \n",
    "        \n",
    "    return vehPos_text\n",
    "\n",
    "def drawLineArea(undist,src,dst,M,left_fit,right_fit):\n",
    "# Function to draw detected lane area\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, undist.shape[0]-1, undist.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # First perspective transform\n",
    "    warped_out = cv2.warpPerspective(undist, M, (np.shape(undist)[1],np.shape(undist)[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Draw lane surface on it\n",
    "    xy_plot = np.zeros((1,np.shape(ploty)[0]*2,2))\n",
    "    xy_plot[:,0:np.shape(ploty)[0],0] = left_fitx\n",
    "    xy_plot[:,0:np.shape(ploty)[0],1] = ploty\n",
    "    xy_plot[:,np.shape(ploty)[0]:,0] = right_fitx[::-1]\n",
    "    xy_plot[:,np.shape(ploty)[0]:,1] = ploty[::-1]\n",
    "\n",
    "    cv2.fillConvexPoly(warped_out, np.int_(xy_plot), (255,0,0))\n",
    "\n",
    "    # Compute inverse perspective transform\n",
    "    invM = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # Unwarp the image\n",
    "    unwarped = cv2.warpPerspective(warped_out, invM, (np.shape(warped_out)[1],np.shape(warped_out)[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Put images together\n",
    "    out_img = cv2.addWeighted(undist, 1, unwarped, 0.3, 0)  \n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#del line_history\n",
    "line_history = Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluate images\n",
    "\n",
    "# Before starting, setup needed once\n",
    "# Load camera calibration\n",
    "dist_pickle = pickle.load(open(\"camera_cal/calibration_dist_pickle.p\", \"rb\"))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read image\n",
    "img = mpimg.imread('test_images/straight_lines2.jpg')\n",
    "\n",
    "######## PARAMETERS ######## \n",
    "ref_right = 940 # reference value for right lane marking (warped image)\n",
    "ref_left = 340 # reference value for left lane marking (warped image)\n",
    "lane_w_pxls = ref_right-ref_left # lane width in pixels\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/lane_w_pxls # meters per pixel in x dimension (pixels is lane width in warped image)\n",
    "# middle of lane should be in the middle of the image (camera is assumed to be centered in vehicle)\n",
    "norm_middle = img.shape[1]/2\n",
    "\n",
    "# Source and distance points from straight camera image, use these for all images\n",
    "src = np.float32([[215, 710], [595, 450], [690, 450], [1100, 710]])\n",
    "dst = np.float32([[ref_left,np.shape(img)[0]], [ref_left,0], [ref_right,0], [ref_right,np.shape(img)[0]]])\n",
    "######## PARAMETERS ######## \n",
    "\n",
    "# Undistort image\n",
    "undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Preprocess image to make search for lane markings easier\n",
    "img_prep = preprocessImage(undist)\n",
    "\n",
    "# Warp image\n",
    "img_warped, M = transformImg(img_prep,src,dst)\n",
    "\n",
    "# Find lane markings when none found before\n",
    "if line_history.detected:\n",
    "        left_fit = line_history.current_fit[0]\n",
    "        right_fit = line_history.current_fit[1]\n",
    "        print(np.shape(left_fit))\n",
    "        print(np.shape(right_fit))\n",
    "        \n",
    "        #If lane markings are already found since before\n",
    "        left_fit,right_fit,leftx,lefty,rightx,righty = findLaneMarkingsCont(img_warped,left_fit,right_fit)\n",
    "      \n",
    "        line_history.current_fit = left_fit,right_fit\n",
    "        \n",
    "else:\n",
    "        # Find lane markings when none found before\n",
    "        left_fit,right_fit,leftx,lefty,rightx,righty = findLaneMarkingsNew(img_warped)\n",
    "        line_history.current_fit = left_fit,right_fit\n",
    "        line_history.detected = True\n",
    "\n",
    "\n",
    "#left_fit,right_fit,leftx,lefty,rightx,righty = findLaneMarkingsNew(img_warped)\n",
    "\n",
    "# If lane markings are already found since before\n",
    "#left_fit, right_fit = findLaneMarkingsCont(img_warped,left_fit,right_fit):\n",
    "\n",
    "# Calculate curvature\n",
    "# Define y-value where we want radius of curvature\n",
    "# I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "y_eval = img_warped.shape[0]\n",
    "left_curveR, right_curveR = detCurvature(y_eval,leftx,lefty,rightx,righty,xm_per_pix,ym_per_pix)\n",
    "\n",
    "# Calculate vehicle position\n",
    "vehPos_text = vehiclePos(norm_middle,right_fit,y_eval,lane_w_pxls,xm_per_pix)\n",
    "\n",
    "# Get image with defined lane area\n",
    "out_image = drawLineArea(undist,src,dst,M,left_fit,right_fit)\n",
    "\n",
    "# Add curvature and vehicle position texts\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "curve_text = 'Left: '+str(round(left_curveR,2)) + 'm. Right: ' + str(round(right_curveR,2)) + 'm.'\n",
    "cv2.putText(out_image, curve_text, (400,50), font, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "cv2.putText(out_image, vehPos_text, (400,100), font, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "# Plot result\n",
    "plt.imshow(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Video pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    # Evaluate images\n",
    "\n",
    "    # Before starting, setup needed once\n",
    "    # Load camera calibration\n",
    "    dist_pickle = pickle.load(open(\"camera_cal/calibration_dist_pickle.p\", \"rb\"))\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "\n",
    "    ######## PARAMETERS ######## \n",
    "    ref_right = 940 # reference value for right lane marking (warped image)\n",
    "    ref_left = 340 # reference value for left lane marking (warped image)\n",
    "    lane_w_pxls = ref_right-ref_left # lane width in pixels\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/lane_w_pxls # meters per pixel in x dimension (pixels is lane width in warped image)\n",
    "    # middle of lane should be in the middle of the image (camera is assumed to be centered in vehicle)\n",
    "    norm_middle = img.shape[1]/2\n",
    "\n",
    "    # Source and distance points from straight camera image, use these for all images\n",
    "    src = np.float32([[215, 710], [595, 450], [690, 450], [1100, 710]])\n",
    "    dst = np.float32([[ref_left,np.shape(img)[0]], [ref_left,0], [ref_right,0], [ref_right,np.shape(img)[0]]])\n",
    "    ######## PARAMETERS ######## \n",
    "\n",
    "    # Undistort image\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # Preprocess image to make search for lane markings easier\n",
    "    img_prep = preprocessImage(undist)\n",
    "\n",
    "    # Warp image\n",
    "    img_warped, M = transformImg(img_prep,src,dst)\n",
    "\n",
    "    \n",
    "    if line_history.detected:\n",
    "        left_fit = line_history.current_fit[0]\n",
    "        right_fit = line_history.current_fit[1]\n",
    "        #If lane markings are already found since before\n",
    "        left_fit,right_fit,leftx,lefty,rightx,righty = findLaneMarkingsCont(img_warped,left_fit,right_fit)\n",
    "        line_history.current_fit = left_fit,right_fit\n",
    "    else:\n",
    "        # Find lane markings when none found before\n",
    "        left_fit,right_fit,leftx,lefty,rightx,righty = findLaneMarkingsNew(img_warped)\n",
    "        line_history.current_fit = left_fit,right_fit\n",
    "        line_history.detected = True\n",
    "\n",
    "\n",
    "    # Calculate curvature\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = img_warped.shape[0]\n",
    "    left_curveR, right_curveR = detCurvature(y_eval,leftx,lefty,rightx,righty,xm_per_pix,ym_per_pix)\n",
    "\n",
    "    # Calculate vehicle position\n",
    "    vehPos_text = vehiclePos(norm_middle,right_fit,y_eval,lane_w_pxls,xm_per_pix)\n",
    "\n",
    "    # Get image with defined lane area\n",
    "    out_image = drawLineArea(undist,src,dst,M,left_fit,right_fit)\n",
    "\n",
    "    # Add curvature and vehicle position texts\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    curve_text = 'Left: '+str(round(left_curveR,2)) + 'm. Right: ' + str(round(right_curveR,2)) + 'm.'\n",
    "    cv2.putText(out_image, curve_text, (400,50), font, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(out_image, vehPos_text, (400,100), font, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del line_history\n",
    "# create Line object\n",
    "line_history = Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v_output = 'harder_challenge_video_edit.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(v_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
